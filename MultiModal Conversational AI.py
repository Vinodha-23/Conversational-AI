# -*- coding: utf-8 -*-
"""Gemini_vinodha.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17PKSylUYuXbIWZrT2KY5ICVa6GinxJ2y

TEXT
"""

!pip install -q -U google-generativeai

import pathlib
import textwrap

import google.generativeai as genai

# Used to securely store your API key
from google.colab import userdata

from IPython.display import display
from IPython.display import Markdown


def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.
GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')

genai.configure(api_key=GOOGLE_API_KEY)

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

model = genai.GenerativeModel('gemini-pro')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# response = model.generate_content("Tell me important incidents that happened in february 2023")

print(response)

response.text

to_markdown(response.text)

response.candidates

response=model.generate_content("Give me a 1000 words essay",stream=True)

for chunk in response:
  print(chunk.text)
  print("_"*80)

!curl -o image.jpg https://t4.ftcdn.net/jpg/03/00/60/99/360_F_300609989_u7T52hYtBKCrCbrPFc92crmcSjfUcL1N.jpg

import PIL.Image

img = PIL.Image.open('image.jpg')
img

"""MULTIMODAL

"""

model = genai.GenerativeModel('gemini-pro-vision')

response = model.generate_content(img)

to_markdown(response.text)

response = model.generate_content(["Write a short, engaging blog post based on this picture.list the name of various types of mushrooms in the image", img], stream=True)
response.resolve()

to_markdown(response.text)

model = genai.GenerativeModel('gemini-pro')
chat = model.start_chat(history=[])
chat

response = chat.send_message("In one sentence, explain how a computer works to a young child.")
to_markdown(response.text)

chat.history

response = chat.send_message("Okay, how about a more detailed explanation to a high schooler?", stream=True)

for chunk in response:
  print(chunk.text)
  print("_"*80)

for message in chat.history:
  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))





